{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fec3159",
   "metadata": {},
   "source": [
    "# Web scraping: THE WORLD FACTBOOK\n",
    "\n",
    "## Introducción\n",
    "\n",
    "\"The World Factbook\" de la CIA es una publicación en línea que proporciona información detallada sobre diversos países y territorios de todo el mundo. Es una referencia ampliamente utilizada y una de las fuentes de información más completas y confiables sobre datos demográficos, geográficos, económicos, políticos y militares de diferentes naciones.  \n",
    "<br>\n",
    "La página web de \"The World Factbook\" de la CIA ofrece un amplio conjunto de datos sobre más de 250 países y territorios (262 para el 14 de junio del 2023). Proporciona información sobre aspectos como la geografía, la población, el gobierno, la economía, las comunicaciones, las fuerzas militares y mucho más. Estos datos incluyen descripciones, estadísticas, gráficos y mapas que permiten obtener una visión general de cada país o territorio.\n",
    "\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "### Generales\n",
    "- Recopilar datos desde una página web por medio de métodos de programación tradicional.\n",
    "\n",
    "### Especifícos\n",
    "- Analizar la estructura del contenidos de la página web `The World Factbook`. \n",
    "- Extraer datos mediante el uso de técnicas de web scrapping utilizando el lenguaje de programación Python.\n",
    "- Modelar y diseñar la base de datos que almacenará los datos sustraidos de la página web `The World factbook`.\n",
    "\n",
    "\n",
    "## Descripción del problema\n",
    "El objetivo de este proyecto es realizar un proceso de Web Scraping en la página web \"[The World factbook](https://www.cia.gov/the-world-factbook/)\" para extraer datos relevantes sobre diversos países. Utilizando el lenguaje de programación Python y la biblioteca BeautifulSoup, se llevará a cabo la extracción y procesamiento de la información disponible en la página web.\n",
    "\n",
    "Una vez obtenidos los datos, se almacenarán en un archivo plano en formato JSON, lo cual permitirá su posterior manipulación y análisis. El siguiente paso consistirá en realizar un proceso de ETL (Extracción, Transformación y Carga) para transferir los datos extraídos desde el archivo JSON a una base de datos relacional.\n",
    "\n",
    "La base de datos relacional será utilizada como fuente de información para responder a las preguntas planteadas en el contexto del proyecto. Mediante consultas a la base de datos, se podrán obtener estadísticas, características y visualizaciones relevantes sobre los países y sus atributos.\n",
    "\n",
    "Este proyecto tiene como finalidad demostrar las habilidades en Web Scraping, procesamiento de datos y manejo de bases de datos relacionales. Además, proporcionará una oportunidad para aplicar técnicas de visualización de datos y responder preguntas analíticas a partir de la información recopilada.\n",
    "\n",
    "A través de este proyecto, se espera que los participantes adquieran experiencia práctica en la obtención de datos, manipulación de información, modelado de datos y generación de conocimiento a partir de los mismos.\n",
    "\n",
    "\n",
    "## 1. - Actividades \n",
    "\n",
    "1. **Exploración del sitio web [The World factbook](https://www.cia.gov/the-world-factbook/)**\n",
    "    - Análisis inicial: Revisar, leer y explorar el sitio web.\n",
    "    - Revisar, leer y explorar la estructura `HTML` del sitio web.\n",
    "    - Reconocer diferentes etiquetas de contenido.\n",
    "    -  **Análisis**: Es necesario estudiar la estructura del `HTML` para la pagina web `The world factbook`, esta estructura es una pauta _inicial-esencial_ para la identificación de las etiquetas  que contienen caracteristicas de interes. Por ejemplo:\n",
    "       - titulos contenidos en etiquetas `<h2></h2>`\n",
    "       - subtitulos contenidos en etiquetas `<h3></h3>`\n",
    "       - parrafos contenidos en etiquetas `<p></p>`\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "2. **Extracción de los datos**\n",
    "    - Haciendo uso de la herramienta `Jupyter Notebook` programar los módulos necesarios que responden a la necesidad de extraer el contenido de la página web.\n",
    "    - Extraer los datos identificados a partir del lenguaje de programación Python utilizando la librería BeautifulSoup.\n",
    "    - Extraer la información de cada uno de los países (historia, población, gobierno, economía, geografía, medio ambiente, comunicaciones, transporte...).\n",
    "    - Mediante el uso de python, hacer un pre procesamiento de los datos (extracción y limpieza, es decir obtener el texto plano sin etiquetas HTML, sin espacios en blanco).\n",
    "    - Guardar los datos para cada país en un archivo (único) plano en formato JSON.\n",
    "    \n",
    "<br>\n",
    "    \n",
    "3. **ETL**\n",
    "    - Mediante el uso de la herramienta de integración de datos, Talend, realizar un ETL (Extracción, Transformación y Carga) al archivo plano en formato JSON que contiene la información de los países.\n",
    "    - Identificar las características relevantes a partir de los datos, aplicando feature engineering, para mapear estos datos con los campos de la base de datos relacional. \n",
    "    - Diseño de la base de datos\n",
    "        - Crear el modelo de la base de datos a partir de la data sustraida (identificación de entidades, atributos, cardinalidad, dominios, etc)\n",
    "        - Esquematizar la base de datos, pasando del modelo relacional al lenguaje de manipulación de datos `DML`\n",
    "\n",
    "<br>\n",
    "\n",
    "4. **Responder a las preguntas para explorar los datos**  \n",
    " \n",
    "    5.1. *Población:*  \n",
    "    - ¿Cuáles son los países más y menos poblados?\n",
    "    - ¿Cuál es la densidad de población promedio por región o continente?\n",
    "    - ¿Cuáles son los países con la tasa de crecimiento demográfico más alta o más baja?  \n",
    "    \n",
    "    5.2. *Economía:*\n",
    "    - ¿Cuáles son las principales economías del mundo en términos de PIB?\n",
    "    - ¿Cuáles son los países con el ingreso per cápita más alto o más bajo?\n",
    "    - ¿Cuáles son los sectores económicos más importantes en diferentes países?  \n",
    "    \n",
    "    5.3. *Geografía:*\n",
    "    - ¿Cuáles son los países más grandes y más pequeños en términos de área?\n",
    "    - ¿Cuál es la longitud de las costas de diferentes países?\n",
    "    - ¿Cuáles son los países con la altitud más alta o más baja?  \n",
    "    \n",
    "    5.4. *Educación:*\n",
    "    - ¿Cuáles son los países con los niveles más altos de alfabetización?\n",
    "    - ¿Cuál es la tasa de matriculación escolar en diferentes países?\n",
    "    - ¿Cuáles son los países con la mayor inversión en educación?  \n",
    "    \n",
    "    5.5. *Salud:*\n",
    "    - ¿Cuál es la esperanza de vida promedio en diferentes países?\n",
    "    - ¿Cuáles son los países con la tasa de mortalidad infantil más alta o más baja?\n",
    "    - ¿Cuáles son los principales problemas de salud en diferentes regiones?\n",
    "\n",
    "<br>\n",
    "\n",
    "5. **Resultados y conclusiones**\n",
    "   - Se espera un único archivo `ipynb` llamado `webScrapingCIA.ipynb`.\n",
    "   - Una carpeta llamada `core` que contendrá los paquetes de programaciñn desarrollados por el estudiante y que responden a la parte de extracción de los datos. \n",
    "   - Una carpeta llamada `data` que contendrá el archivo plano en formato JSON con la información extraída del sitio web [The World factbook](https://www.cia.gov/the-world-factbook/).\n",
    "   - Una carpeta llamada `SQL` que contendrá la definición de la base datos, la solución a las preguntas exploratorias y el modelo relacional de la base de datos que será exportado aplicando ingeniería inversa a la base de datos mediante la herramienta de visualizaciñn de MySQL.\n",
    "   - Una carpeta llamada `ETL` que contendrá el JOB \n",
    "   - El siguiente es un ejemplo de la estructura de carpetas de lo esperado:  \n",
    "     - ETL\n",
    "       - `world-factbook.item`\n",
    "     - SQL\n",
    "       - `dml-web-scraping.sql`\n",
    "       - `ddl-web-scraping.sql`\n",
    "       - `eer.png`\n",
    "     - data\n",
    "       - `world-factbook.json`\n",
    "     - core\n",
    "       - `ExtractHTML.py`\n",
    "       - `ProcessHTML.py`\n",
    "       - `Tools.py`\n",
    "       - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac676d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.ExtractHTML import ExtractHTML\n",
    "from core.Country import Country\n",
    "from core.ProcessHTML import ProcessHTML\n",
    "from core.Tools import Tools\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98af0ea5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado con exito\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    baseURL = \"https://www.cia.gov/the-world-factbook/countries\"\n",
    "    \n",
    "    tools = Tools()\n",
    "    RAWCountries = tools.readFile(path=\".\", name=\"countries.txt\")\n",
    "    \n",
    "    j_son = {}\n",
    "    \n",
    "    country = Country(baseURL)\n",
    "    countries = country.getCountries(RAWCountries)\n",
    "    urlsWorldFactbook = country.formURLofWebPage(countries)\n",
    "    urlCountries = urlsWorldFactbook\n",
    "\n",
    "    HTML = ExtractHTML()\n",
    "    \n",
    "    for i, urlCountry in enumerate(urlCountries[:50]):\n",
    "#     for i, urlCountry in enumerate(urlCountries):\n",
    "        \n",
    "        countryContent = {}\n",
    "        HTMLCountry = HTML.extactHTML(urlCountry)\n",
    "\n",
    "        if HTMLCountry:\n",
    "\n",
    "            processHTML = ProcessHTML()\n",
    "            subtitlesContent = processHTML.unwrapDiv(HTMLCountry=HTMLCountry)\n",
    "            subtitles = processHTML.getSubtitles(subtitlesContent)\n",
    "            divContent = [ tag.find_all(\"div\") for tag in subtitlesContent ]\n",
    "            processDivContent = [ processHTML.filterContentByH3(div) for div in divContent ] \n",
    "\n",
    "\n",
    "            for j, subtitlesContent in enumerate(processDivContent): \n",
    "\n",
    "                subtitle = tools.formatKey( subtitles[j] ) \n",
    "                countryContent[subtitle] = processHTML.formData(subtitlesContent)\n",
    "        \n",
    "            j_son[countries[i]] = countryContent\n",
    "    \n",
    "    tools.saveFile(path=\"./data\", name=\"world-factbook.json\", data=json.dumps(j_son))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e0cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54cde8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.readFile(path=\"./data\", name=\"world-factbook.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
